{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Model: BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based off: https://www.kaggle.com/phoenix9032/pytorch-bert-plain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from math import floor, ceil\n",
    "from scipy.stats import spearmanr\n",
    "from torch.utils.data import DataLoader, Dataset, RandomSampler\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from transformers import (BertPreTrainedModel, BertTokenizer, BertConfig, \n",
    "                          BertModel, get_cosine_schedule_with_warmup\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed: int):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load the data \n",
    "data = Path('data')\n",
    "train = pd.read_csv(data/'train.csv')\n",
    "test = pd.read_csv(data/'test.csv')\n",
    "sub = pd.read_csv(data/'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = ['question_asker_intent_understanding', 'question_body_critical', \n",
    "               'question_conversational', 'question_expect_short_answer', \n",
    "               'question_fact_seeking', 'question_has_commonly_accepted_answer', \n",
    "               'question_interestingness_others', 'question_interestingness_self', \n",
    "               'question_multi_intent', 'question_not_really_a_question', \n",
    "               'question_opinion_seeking', 'question_type_choice',\n",
    "               'question_type_compare', 'question_type_consequence',\n",
    "               'question_type_definition', 'question_type_entity', \n",
    "               'question_type_instructions', 'question_type_procedure', \n",
    "               'question_type_reason_explanation', 'question_type_spelling', \n",
    "               'question_well_written', 'answer_helpful',\n",
    "               'answer_level_of_information', 'answer_plausible', \n",
    "               'answer_relevance', 'answer_satisfaction', \n",
    "               'answer_type_instructions', 'answer_type_procedure', \n",
    "               'answer_type_reason_explanation', 'answer_well_written']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PipeLineConfig:\n",
    "    def __init__(self, lr, warmup, accum_steps, epochs, seed, expname,head_tail,freeze,question_weight,answer_weight,fold,train):\n",
    "        self.lr = lr\n",
    "        self.warmup = warmup\n",
    "        self.accum_steps = accum_steps\n",
    "        self.epochs = epochs\n",
    "        self.seed = seed\n",
    "        self.expname = expname\n",
    "        self.head_tail = head_tail\n",
    "        self.freeze = freeze\n",
    "        self.question_weight = question_weight\n",
    "        self.answer_weight =answer_weight\n",
    "        self.fold = fold\n",
    "        self.train = train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = PipeLineConfig(lr=3e-5, \n",
    "                          warmup=0.05, \n",
    "                          accum_steps=4, \n",
    "                          epochs=1, \n",
    "                          seed=42, \n",
    "                          expname='uncased_1',\n",
    "                          head_tail=True, \n",
    "                          freeze=False, \n",
    "                          question_weight=0.7, \n",
    "                          answer_weight=0.3, \n",
    "                          fold=3, \n",
    "                          train=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the Ref Kernel's\n",
    "\n",
    "def _get_masks(tokens, max_seq_length):\n",
    "    \"\"\"Mask for padding\"\"\"\n",
    "    if len(tokens)>max_seq_length:\n",
    "        raise IndexError(\"Token length more than max seq length!\")\n",
    "    return [1]*len(tokens) + [0] * (max_seq_length - len(tokens))\n",
    "\n",
    "def _get_segments(tokens, max_seq_length):\n",
    "    \"\"\"Segments: 0 for the first sequence, 1 for the second\"\"\"\n",
    "    \n",
    "    if len(tokens) > max_seq_length:\n",
    "        raise IndexError(\"Token length more than max seq length!\")\n",
    "        \n",
    "    segments = []\n",
    "    first_sep = True\n",
    "    current_segment_id = 0\n",
    "    \n",
    "    for token in tokens:\n",
    "        segments.append(current_segment_id)\n",
    "        if token == \"[SEP]\":\n",
    "            if first_sep:\n",
    "                first_sep = False \n",
    "            else:\n",
    "                current_segment_id = 1\n",
    "    return segments + [0] * (max_seq_length - len(tokens))\n",
    "\n",
    "def _get_ids(tokens, tokenizer, max_seq_length):\n",
    "    \"\"\"Token ids from Tokenizer vocab\"\"\"\n",
    "    \n",
    "    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    input_ids = token_ids + [0] * (max_seq_length-len(token_ids))\n",
    "    return input_ids\n",
    "\n",
    "def _trim_input(title, question, answer, max_sequence_length=290, t_max_len=30, q_max_len=128, a_max_len=128):\n",
    "    \n",
    "    #350+128+30 = 508 + 4 = 512\n",
    "    \n",
    "    t = tokenizer.tokenize(title)\n",
    "    q = tokenizer.tokenize(question)\n",
    "    a = tokenizer.tokenize(answer)\n",
    "    \n",
    "    t_len = len(t)\n",
    "    q_len = len(q)\n",
    "    a_len = len(a)\n",
    "\n",
    "    if (t_len+q_len+a_len+4) > max_sequence_length:\n",
    "        \n",
    "        if t_max_len > t_len:\n",
    "            t_new_len = t_len\n",
    "            a_max_len = a_max_len + floor((t_max_len - t_len)/2)\n",
    "            q_max_len = q_max_len + ceil((t_max_len - t_len)/2)\n",
    "        else:\n",
    "            t_new_len = t_max_len\n",
    "      \n",
    "        if a_max_len > a_len:\n",
    "            a_new_len = a_len \n",
    "            q_new_len = q_max_len + (a_max_len - a_len)\n",
    "        elif q_max_len > q_len:\n",
    "            a_new_len = a_max_len + (q_max_len - q_len)\n",
    "            q_new_len = q_len\n",
    "        else:\n",
    "            a_new_len = a_max_len\n",
    "            q_new_len = q_max_len\n",
    "            \n",
    "            \n",
    "        if t_new_len+a_new_len+q_new_len+4 != max_sequence_length:\n",
    "            raise ValueError(\"New sequence length should be %d, but is %d\"%(max_sequence_length, (t_new_len + a_new_len + q_new_len + 4)))\n",
    "        q_len_head = round(q_new_len/2)\n",
    "        q_len_tail = -1* (q_new_len -q_len_head)\n",
    "        a_len_head = round(a_new_len/2)\n",
    "        a_len_tail = -1* (a_new_len -a_len_head)        ## Head+Tail method .\n",
    "        t = t[:t_new_len]\n",
    "        if config.head_tail :\n",
    "            q = q[:q_len_head]+q[q_len_tail:]\n",
    "            a = a[:a_len_head]+a[a_len_tail:]\n",
    "        else:\n",
    "            q = q[:q_new_len]\n",
    "            a = a[:a_new_len] ## No Head+Tail ,usual processing\n",
    "    \n",
    "    return t, q, a\n",
    "\n",
    "def _convert_to_bert_inputs(title, question, answer, tokenizer, max_sequence_length):\n",
    "    \"\"\"Converts tokenized input to ids, masks and segments for BERT\"\"\"\n",
    "    \n",
    "    stoken = [\"[CLS]\"] + title + [\"[SEP]\"] + question + [\"[SEP]\"] + answer + [\"[SEP]\"]\n",
    "   # stoken = [\"[CLS]\"] + title  + question  + answer + [\"[SEP]\"]\n",
    "\n",
    "    input_ids = _get_ids(stoken, tokenizer, max_sequence_length)\n",
    "    input_masks = _get_masks(stoken, max_sequence_length)\n",
    "    input_segments = _get_segments(stoken, max_sequence_length)\n",
    "\n",
    "    return [input_ids, input_masks, input_segments]\n",
    "\n",
    "def _get_stoken_output(title, question, answer, tokenizer, max_sequence_length):\n",
    "    \"\"\"Converts tokenized input to ids, masks and segments for BERT\"\"\"\n",
    "    \n",
    "    stoken = [\"[CLS]\"] + title + [\"[SEP]\"] + question + [\"[SEP]\"] + answer + [\"[SEP]\"]\n",
    "    return stoken\n",
    "\n",
    "def compute_input_tokens(df, columns, tokenizer, max_sequence_length):\n",
    "    \n",
    "    input_tokens, input_masks, input_segments = [], [], []\n",
    "    for _, instance in df[columns].iterrows():\n",
    "        t, q, a = instance.question_title, instance.question_body, instance.answer\n",
    "        t, q, a = _trim_input(t, q, a, max_sequence_length)\n",
    "        tokens= _get_stoken_output(t, q, a, tokenizer, max_sequence_length)\n",
    "        input_tokens.append(tokens)\n",
    "    return input_tokens\n",
    "\n",
    "def compute_input_arays(df, columns, tokenizer, max_sequence_length,t_max_len=30, q_max_len=128, a_max_len=128):\n",
    "    \n",
    "    input_ids, input_masks, input_segments = [], [], []\n",
    "    for _, instance in df[columns].iterrows():\n",
    "        t, q, a = instance.question_title, instance.question_body, instance.answer\n",
    "        t, q, a = _trim_input(t, q, a, max_sequence_length,t_max_len, q_max_len, a_max_len)\n",
    "        ids, masks, segments = _convert_to_bert_inputs(t, q, a, tokenizer, max_sequence_length)\n",
    "        input_ids.append(ids)\n",
    "        input_masks.append(masks)\n",
    "        input_segments.append(segments)\n",
    "    return [\n",
    "        torch.from_numpy(np.asarray(input_ids, dtype=np.int32)).long(), \n",
    "        torch.from_numpy(np.asarray(input_masks, dtype=np.int32)).long(),\n",
    "        torch.from_numpy(np.asarray(input_segments, dtype=np.int32)).long(),\n",
    "    ]\n",
    "\n",
    "def compute_output_arrays(df, columns):\n",
    "    return np.asarray(df[columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, inputs, lengths, labels = None):\n",
    "        \n",
    "        self.inputs = inputs\n",
    "        if labels is not None:\n",
    "            self.labels = labels\n",
    "        else:\n",
    "            self.labels = None\n",
    "        self.lengths = lengths\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        input_ids       = self.inputs[0][idx]\n",
    "        input_masks     = self.inputs[1][idx]\n",
    "        input_segments  = self.inputs[2][idx]\n",
    "        lengths         = self.lengths[idx]\n",
    "        if self.labels is not None: # targets\n",
    "            labels = self.labels[idx]\n",
    "            return input_ids, input_masks, input_segments, labels, lengths\n",
    "        return input_ids, input_masks, input_segments, lengths\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Stolen from transformer code base without any noble intention.\n",
    "class CustomBert(BertPreTrainedModel):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super(CustomBert, self).__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "\n",
    "        self.bert = BertModel(config)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.bn = nn.BatchNorm1d(1024)\n",
    "        self.linear  = nn.Linear(config.hidden_size,1024)\n",
    "        self.classifier = nn.Linear(1024, self.config.num_labels)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        labels=None,\n",
    "    ):\n",
    "\n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "        )\n",
    "\n",
    "        pooled_output = outputs[1]\n",
    "\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        lin_output = F.relu(self.bn(self.linear(pooled_output))) ## Note : This Linear layer is added without expert supervision . This will worsen the results . \n",
    "                                               ## But you are smarter than me , so you will figure out,how to customize better.\n",
    "        lin_output = self.dropout(lin_output)    \n",
    "        logits = self.classifier(lin_output)\n",
    "\n",
    "        outputs = (logits,) + outputs[2:]  # add hidden states and attention if they are here\n",
    "\n",
    "        if labels is not None:\n",
    "            if self.num_labels == 1:\n",
    "                #  We are doing regression\n",
    "                loss_fct = MSELoss()\n",
    "                loss = loss_fct(logits.view(-1), labels.view(-1))\n",
    "            else:\n",
    "                loss_fct = CrossEntropyLoss()\n",
    "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            outputs = (loss,) + outputs\n",
    "\n",
    "        return outputs  # (loss), logits, (hidden_states), (attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_loader, optimizer, criterion, scheduler,config):\n",
    "    \n",
    "    model.train()\n",
    "    avg_loss = 0.\n",
    "    avg_loss_1 = 0.\n",
    "    avg_loss_2 =0.\n",
    "    avg_loss_3 =0.\n",
    "    avg_loss_4 =0.\n",
    "    avg_loss_5 =0.\n",
    "   # tk0 = tqdm(enumerate(train_loader),total =len(train_loader))\n",
    "    optimizer.zero_grad()\n",
    "    for idx, batch in enumerate(train_loader):\n",
    "        \n",
    "        input_ids, input_masks, input_segments, labels, _ = batch\n",
    "        input_ids, input_masks, input_segments, labels = input_ids.to(device), input_masks.to(device), input_segments.to(device), labels.to(device)            \n",
    "        \n",
    "        output_train = model(input_ids = input_ids.long(),\n",
    "                             labels = None,\n",
    "                             attention_mask = input_masks,\n",
    "                             token_type_ids = input_segments,\n",
    "                            )\n",
    "        logits = output_train[0] #output preds\n",
    "        loss1 = criterion(logits[:,0:9], labels[:,0:9])\n",
    "        loss2 = criterion(logits[:,9:10], labels[:,9:10])\n",
    "        loss3 = criterion(logits[:,10:21], labels[:,10:21])\n",
    "        loss4 = criterion(logits[:,21:26], labels[:,21:26])\n",
    "        loss5 = criterion(logits[:,26:30], labels[:,26:30])\n",
    "        loss = config.question_weight*loss1+config.answer_weight*loss2+config.question_weight*loss3+config.answer_weight*loss4+config.question_weight*loss5\n",
    "        #loss =(config.question_weight*criterion(logits[:,0:21], labels[:,0:21]) + config.answer_weight*criterion(logits[:,21:30], labels[:,21:30]))/config.accum_steps\n",
    "        loss.backward()\n",
    "        if (i + 1) % config.accum_steps == 0:    \n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        avg_loss += loss.item() / (len(train_loader)*config.accum_steps)\n",
    "        avg_loss_1 += loss1.item() / (len(train_loader)*config.accum_steps)\n",
    "        avg_loss_2 += loss2.item() / (len(train_loader)*config.accum_steps)\n",
    "        avg_loss_3 += loss3.item() / (len(train_loader)*config.accum_steps)\n",
    "        avg_loss_4 += loss4.item() / (len(train_loader)*config.accum_steps)\n",
    "        avg_loss_5 += loss5.item() / (len(train_loader)*config.accum_steps)\n",
    "        del input_ids, input_masks, input_segments, labels\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    return avg_loss ,avg_loss_1,avg_loss_2,avg_loss_3,avg_loss_4,avg_loss_5\n",
    "\n",
    "def val_model(val_loader, val_shape, batch_size=8):\n",
    "\n",
    "    avg_val_loss = 0.\n",
    "    model.eval() # eval mode\n",
    "    \n",
    "    valid_preds = np.zeros((val_shape, len(target_cols)))\n",
    "    original = np.zeros((val_shape, len(target_cols)))\n",
    "    \n",
    "    #tk0 = tqdm(enumerate(val_loader))\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for idx, batch in enumerate(val_loader):\n",
    "            input_ids, input_masks, input_segments, labels, _ = batch\n",
    "            input_ids, input_masks, input_segments, labels = input_ids.to(device), input_masks.to(device), input_segments.to(device), labels.to(device)            \n",
    "            \n",
    "            output_val = model(input_ids = input_ids.long(),\n",
    "                             labels = None,\n",
    "                             attention_mask = input_masks,\n",
    "                             token_type_ids = input_segments,\n",
    "                            )\n",
    "            logits = output_val[0] #output preds\n",
    "            \n",
    "            avg_val_loss += criterion(logits, labels).item() / len(val_loader)\n",
    "            valid_preds[idx*batch_size : (idx+1)*batch_size] = logits.detach().cpu().squeeze().numpy()\n",
    "            original[idx*batch_size : (idx+1)*batch_size]    = labels.detach().cpu().squeeze().numpy()\n",
    "        \n",
    "        score = 0\n",
    "        preds = torch.sigmoid(torch.tensor(valid_preds)).numpy()\n",
    "        \n",
    "        # np.save(\"preds.npy\", preds)\n",
    "        # np.save(\"actuals.npy\", original)\n",
    "        \n",
    "        rho_val = np.mean([spearmanr(original[:, i], preds[:,i]).correlation for i in range(preds.shape[1])])\n",
    "        print('\\r val_spearman-rho: %s' % (str(round(rho_val, 5))), end = 100*' '+'\\n')\n",
    "        \n",
    "        for i in range(len(target_cols)):\n",
    "            print(i, spearmanr(original[:,i], preds[:,i]))\n",
    "            score += np.nan_to_num(spearmanr(original[:, i], preds[:, i]).correlation)\n",
    "    return avg_val_loss, score/len(target_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_result(model, test_loader, batch_size=32):\n",
    "    \n",
    "    test_preds = np.zeros((len(test), len(target_cols)))\n",
    "    \n",
    "    model.eval();\n",
    "    tk0 = tqdm(enumerate(test_loader))\n",
    "    for idx, x_batch in tk0:\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids = x_batch[0].to(device), \n",
    "                            labels = None, \n",
    "                            attention_mask = x_batch[1].to(device),\n",
    "                            token_type_ids = x_batch[2].to(device),\n",
    "                           )\n",
    "            predictions = outputs[0]\n",
    "            test_preds[idx*batch_size : (idx+1)*batch_size] = predictions.detach().cpu().squeeze().numpy()\n",
    "\n",
    "    output = torch.sigmoid(torch.tensor(test_preds)).numpy()        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True bert-base-uncased cuda bert_pytorch.bin\n",
      "[tensor([[  101,  2097,  2975,  ...,     0,     0,     0],\n",
      "        [  101, 24471,  2140,  ...,     0,     0,     0],\n",
      "        [  101,  2003, 10640,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 29296,  8241,  ...,     0,     0,     0],\n",
      "        [  101,  2003,  1037,  ...,     0,     0,     0],\n",
      "        [  101,  2424,  2814,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]])]\n",
      "True bert-base-uncased cuda bert_pytorch.bin\n",
      "[tensor([[  101,  2097,  2975,  ...,     0,     0,     0],\n",
      "        [  101, 24471,  2140,  ...,     0,     0,     0],\n",
      "        [  101,  2003, 10640,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 29296,  8241,  ...,  3145,  1012,   102],\n",
      "        [  101,  2003,  1037,  ...,  2505,  1012,   102],\n",
      "        [  101,  2424,  2814,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]])]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"data/bert-base-uncased-vocab.txt\", do_lower_case=True)\n",
    "input_categories = list(train.columns[[1,2,5]]); input_categories\n",
    "\n",
    "bert_model_config = 'data/bert-base-uncased/bert_config.json'\n",
    "bert_config = BertConfig.from_json_file(bert_model_config)\n",
    "bert_config.num_labels = len(target_cols)\n",
    "\n",
    "\n",
    "bert_model = 'bert-base-uncased'\n",
    "do_lower_case = 'uncased' in bert_model\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "output_model_file = 'bert_pytorch.bin'\n",
    "\n",
    "\n",
    "test_inputs = compute_input_arays(test, input_categories, tokenizer, max_sequence_length=512,t_max_len=30, q_max_len=239, a_max_len=239)\n",
    "lengths_test = np.argmax(test_inputs[0] == 0, axis=1)\n",
    "lengths_test[lengths_test == 0] = test_inputs[0].shape[1]\n",
    "\n",
    "print(do_lower_case, bert_model, device, output_model_file)\n",
    "print(test_inputs)\n",
    "\n",
    "test_set = QuestDataset(inputs=test_inputs, lengths=lengths_test, labels=None)\n",
    "test_loader  = DataLoader(test_set, batch_size=32, shuffle=False)\n",
    "result = np.zeros((len(test), len(target_cols)))\n",
    "\n",
    "test_inputs = compute_input_arays(test, input_categories, tokenizer, max_sequence_length=290,t_max_len=30, q_max_len=128, a_max_len=128)\n",
    "lengths_test = np.argmax(test_inputs[0] == 0, axis=1)\n",
    "lengths_test[lengths_test == 0] = test_inputs[0].shape[1]\n",
    "\n",
    "print(do_lower_case, bert_model, device, output_model_file)\n",
    "print(test_inputs)\n",
    "\n",
    "test_set1 = QuestDataset(inputs=test_inputs, lengths=lengths_test, labels=None)\n",
    "test_loader1  = DataLoader(test_set, batch_size=32, shuffle=False)\n",
    "result1 = np.zeros((len(test), len(target_cols)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bcolors:\n",
    "    HEADER = '\\033[95m'\n",
    "    OKBLUE = '\\033[94m'\n",
    "    OKGREEN = '\\033[92m'\n",
    "    WARNING = '\\033[93m'\n",
    "    FAIL = '\\033[91m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m For Every Fold, Train 1 Epochs \u001b[0m\n",
      "\u001b[95m Current Fold: 0 \u001b[0m\n",
      "Train and Valid Shapes are (4053, 41) (2026, 41)\n",
      "\u001b[95m Preparing train datasets.... \u001b[0m\n",
      "\u001b[95m Preparing Valid datasets.... \u001b[0m\n",
      "\u001b[95m Preparing Dataloaders Datasets.... \u001b[0m\n",
      "Training....\n",
      " val_spearman-rho: -0.00706                                                                                                    \n",
      "0 SpearmanrResult(correlation=-0.03930638914549745, pvalue=0.07692461102971908)\n",
      "1 SpearmanrResult(correlation=-0.09401290181422674, pvalue=2.2511508557265573e-05)\n",
      "2 SpearmanrResult(correlation=0.016881628696759056, pvalue=0.44758580186822905)\n",
      "3 SpearmanrResult(correlation=-0.016910123783945488, pvalue=0.44681949684347977)\n",
      "4 SpearmanrResult(correlation=0.05788959198298659, pvalue=0.009153897334933972)\n",
      "5 SpearmanrResult(correlation=0.0004378287787308058, pvalue=0.9842866811930274)\n",
      "6 SpearmanrResult(correlation=-0.0805392354182009, pvalue=0.0002847206165638837)\n",
      "7 SpearmanrResult(correlation=-0.02635903166783967, pvalue=0.2356526739862361)\n",
      "8 SpearmanrResult(correlation=-0.0948479867489926, pvalue=1.900920946985795e-05)\n",
      "9 SpearmanrResult(correlation=-0.021665531459801855, pvalue=0.32970801525141136)\n",
      "10 SpearmanrResult(correlation=-0.05208166235560384, pvalue=0.019057834119956027)\n",
      "11 SpearmanrResult(correlation=0.08335030285377039, pvalue=0.00017271197893271067)\n",
      "12 SpearmanrResult(correlation=-0.07237279843972641, pvalue=0.001114731623779831)\n",
      "13 SpearmanrResult(correlation=-0.015249825088822434, pvalue=0.4926955665476578)\n",
      "14 SpearmanrResult(correlation=0.021061214949106927, pvalue=0.3433796289278408)\n",
      "15 SpearmanrResult(correlation=0.06817147824363208, pvalue=0.0021394972722019647)\n",
      "16 SpearmanrResult(correlation=0.12385650653179692, pvalue=2.2314619503264675e-08)\n",
      "17 SpearmanrResult(correlation=-0.017201146484636845, pvalue=0.4390359947152771)\n",
      "18 SpearmanrResult(correlation=0.02726887219685224, pvalue=0.21987039040190778)\n",
      "19 SpearmanrResult(correlation=0.04338392166033232, pvalue=0.050882124898628)\n",
      "20 SpearmanrResult(correlation=-0.023058967959561496, pvalue=0.2995461637077899)\n",
      "21 SpearmanrResult(correlation=0.012686016837246232, pvalue=0.5682150486828574)\n",
      "22 SpearmanrResult(correlation=0.011558915182237686, pvalue=0.6030803888784748)\n",
      "23 SpearmanrResult(correlation=0.01762654176821249, pvalue=0.42779986837412)\n",
      "24 SpearmanrResult(correlation=-0.06804882470543994, pvalue=0.002179499737087346)\n",
      "25 SpearmanrResult(correlation=-0.08769269027426646, pvalue=7.739549887684126e-05)\n",
      "26 SpearmanrResult(correlation=-0.07079736028773416, pvalue=0.0014291274260351172)\n",
      "27 SpearmanrResult(correlation=0.05307425827265177, pvalue=0.01688782624150323)\n",
      "28 SpearmanrResult(correlation=-0.019572070581509005, pvalue=0.37858782105184396)\n",
      "29 SpearmanrResult(correlation=0.05075755097333108, pvalue=0.022329460837998857)\n",
      "\u001b[92m Epoch 1/1 \t loss=0.4981 \t val_loss=0.6996 \t train_loss=0.4981 \t train_loss_1=0.1781 \t train_loss_2=0.1770 \t train_loss_3=0.1814 \t train_loss_4=0.1716  \t train_loss_5=0.2027 \t score=-0.007057 \t time=151.86s \u001b[0m\n",
      "best_param_score_uncased_1_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [00:09,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_param_score_uncased_1_1.pt\n"
     ]
    }
   ],
   "source": [
    "NUM_FOLDS = config.fold  # change this\n",
    "SEED = config.seed\n",
    "BATCH_SIZE = 8\n",
    "epochs = config.epochs   # change this\n",
    "ACCUM_STEPS = 1\n",
    "\n",
    "kf = MultilabelStratifiedKFold(n_splits = NUM_FOLDS, random_state = SEED)\n",
    "\n",
    "#test_set = QuestDataset(inputs=test_inputs, lengths=lengths_test, labels=None)\n",
    "#test_loader  = DataLoader(test_set, batch_size=32, shuffle=False)\n",
    "#result = np.zeros((len(test), len(target_cols)))\n",
    "\n",
    "y_train = train[target_cols].values # dummy\n",
    "\n",
    "print(bcolors.FAIL, f\"For Every Fold, Train {epochs} Epochs\", bcolors.ENDC)\n",
    "if config.train :\n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(train.values, y_train)):\n",
    "        if fold > 0 : ## Saving GPU\n",
    "            break \n",
    "        print(bcolors.HEADER, \"Current Fold:\", fold, bcolors.ENDC)\n",
    "\n",
    "        train_df, val_df = train.iloc[train_index], train.iloc[val_index]\n",
    "        print(\"Train and Valid Shapes are\", train_df.shape, val_df.shape)\n",
    "    \n",
    "        print(bcolors.HEADER, \"Preparing train datasets....\", bcolors.ENDC)\n",
    "    \n",
    "        inputs_train = compute_input_arays(train_df, input_categories, tokenizer, max_sequence_length=290)\n",
    "        outputs_train = compute_output_arrays(train_df, columns = target_cols)\n",
    "        outputs_train = torch.tensor(outputs_train, dtype=torch.float32)\n",
    "        lengths_train = np.argmax(inputs_train[0] == 0, axis=1)\n",
    "        lengths_train[lengths_train == 0] = inputs_train[0].shape[1]\n",
    "    \n",
    "        print(bcolors.HEADER, \"Preparing Valid datasets....\", bcolors.ENDC)\n",
    "    \n",
    "        inputs_valid = compute_input_arays(val_df, input_categories, tokenizer, max_sequence_length=290)\n",
    "        outputs_valid = compute_output_arrays(val_df, columns = target_cols)\n",
    "        outputs_valid = torch.tensor(outputs_valid, dtype=torch.float32)\n",
    "        lengths_valid = np.argmax(inputs_valid[0] == 0, axis=1)\n",
    "        lengths_valid[lengths_valid == 0] = inputs_valid[0].shape[1]\n",
    "    \n",
    "        print(bcolors.HEADER, \"Preparing Dataloaders Datasets....\", bcolors.ENDC)\n",
    "\n",
    "        train_set    = QuestDataset(inputs=inputs_train, lengths=lengths_train, labels=outputs_train)\n",
    "        train_sampler = RandomSampler(train_set)\n",
    "        train_loader = DataLoader(train_set, batch_size=BATCH_SIZE,sampler=train_sampler)\n",
    "    \n",
    "        valid_set    = QuestDataset(inputs=inputs_valid, lengths=lengths_valid, labels=outputs_valid)\n",
    "        valid_loader = DataLoader(valid_set, batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n",
    "    \n",
    "        model = CustomBert.from_pretrained('data/bert-base-uncased/', config=bert_config);\n",
    "        model.zero_grad();\n",
    "        model.to(device);\n",
    "        torch.cuda.empty_cache()\n",
    "        if config.freeze : ## This is basically using out of the box bert model while training only the classifier head with our data . \n",
    "            for param in model.bert.parameters():\n",
    "                param.requires_grad = False\n",
    "        model.train();\n",
    "    \n",
    "        i = 0\n",
    "        best_avg_loss   = 100.0\n",
    "        best_score      = -1.\n",
    "        best_param_loss = None\n",
    "        best_param_score = None\n",
    "        param_optimizer = list(model.named_parameters())\n",
    "        no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "        optimizer_grouped_parameters = [\n",
    "            {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.8},\n",
    "            {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "            ]        \n",
    "\n",
    "        optimizer = torch.optim.AdamW(optimizer_grouped_parameters, lr=config.lr, eps=4e-5)\n",
    "       # optimizer = torch.optim.AdamW(model.parameters(), lr=config.lr, eps=4e-5)\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "        scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=config.warmup, num_training_steps= epochs*len(train_loader)//ACCUM_STEPS)\n",
    "        print(\"Training....\")\n",
    "    \n",
    "        for epoch in range(config.epochs):\n",
    "\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "            start_time   = time.time()\n",
    "            avg_loss,avg_loss_1,avg_loss_2 ,avg_loss_3,avg_loss_4,avg_loss_5   = train_model(train_loader, optimizer, criterion, scheduler,config)\n",
    "            avg_val_loss, score = val_model(valid_loader, val_shape=val_df.shape[0])\n",
    "            elapsed_time = time.time() - start_time\n",
    "\n",
    "            print(bcolors.OKGREEN, 'Epoch {}/{} \\t loss={:.4f} \\t val_loss={:.4f} \\t train_loss={:.4f} \\t train_loss_1={:.4f} \\t train_loss_2={:.4f} \\t train_loss_3={:.4f} \\t train_loss_4={:.4f}  \\t train_loss_5={:.4f} \\t score={:.6f} \\t time={:.2f}s'.format(\n",
    "                epoch + 1, epochs, avg_loss, avg_val_loss,avg_loss,avg_loss_1,avg_loss_2,avg_loss_3,avg_loss_4,avg_loss_5, score, elapsed_time),\n",
    "            bcolors.ENDC\n",
    "            )\n",
    "\n",
    "            if best_avg_loss > avg_val_loss:\n",
    "                i = 0\n",
    "                best_avg_loss = avg_val_loss \n",
    "                best_param_loss = model.state_dict()\n",
    "\n",
    "            if best_score < score:\n",
    "                best_score = score\n",
    "                best_param_score = model.state_dict()\n",
    "                print('best_param_score_{}_{}.pt'.format(config.expname ,fold+1))\n",
    "                torch.save(best_param_score, 'best_param_score_{}_{}.pt'.format(config.expname ,fold+1))\n",
    "            else:\n",
    "                i += 1\n",
    "\n",
    "            \n",
    "        model.load_state_dict(best_param_score)\n",
    "        result += predict_result(model, test_loader)\n",
    "        print('best_param_score_{}_{}.pt'.format(config.expname ,fold+1))\n",
    "        torch.save(best_param_score, 'best_param_score_{}_{}.pt'.format(config.expname ,fold+1))\n",
    "        \n",
    "        result /= NUM_FOLDS\n",
    "        \n",
    "    del train_df, val_df, model, optimizer, criterion, scheduler\n",
    "    torch.cuda.empty_cache()\n",
    "    del valid_loader, train_loader, valid_set, train_set\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qa_id</th>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <th>question_body_critical</th>\n",
       "      <th>question_conversational</th>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <th>question_multi_intent</th>\n",
       "      <th>...</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>0.167708</td>\n",
       "      <td>0.175055</td>\n",
       "      <td>0.166137</td>\n",
       "      <td>0.160509</td>\n",
       "      <td>0.170683</td>\n",
       "      <td>0.165364</td>\n",
       "      <td>0.169331</td>\n",
       "      <td>0.178417</td>\n",
       "      <td>0.161578</td>\n",
       "      <td>...</td>\n",
       "      <td>0.168833</td>\n",
       "      <td>0.172993</td>\n",
       "      <td>0.163021</td>\n",
       "      <td>0.167236</td>\n",
       "      <td>0.153434</td>\n",
       "      <td>0.164209</td>\n",
       "      <td>0.173853</td>\n",
       "      <td>0.177635</td>\n",
       "      <td>0.161870</td>\n",
       "      <td>0.158824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>0.198516</td>\n",
       "      <td>0.156672</td>\n",
       "      <td>0.175136</td>\n",
       "      <td>0.164823</td>\n",
       "      <td>0.160392</td>\n",
       "      <td>0.175942</td>\n",
       "      <td>0.164311</td>\n",
       "      <td>0.191221</td>\n",
       "      <td>0.169924</td>\n",
       "      <td>...</td>\n",
       "      <td>0.168358</td>\n",
       "      <td>0.176660</td>\n",
       "      <td>0.169892</td>\n",
       "      <td>0.177875</td>\n",
       "      <td>0.171899</td>\n",
       "      <td>0.178268</td>\n",
       "      <td>0.158517</td>\n",
       "      <td>0.185142</td>\n",
       "      <td>0.171573</td>\n",
       "      <td>0.149247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>0.174805</td>\n",
       "      <td>0.162797</td>\n",
       "      <td>0.169590</td>\n",
       "      <td>0.162258</td>\n",
       "      <td>0.162173</td>\n",
       "      <td>0.167899</td>\n",
       "      <td>0.162903</td>\n",
       "      <td>0.172595</td>\n",
       "      <td>0.162429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.163683</td>\n",
       "      <td>0.168201</td>\n",
       "      <td>0.165504</td>\n",
       "      <td>0.171961</td>\n",
       "      <td>0.162536</td>\n",
       "      <td>0.172516</td>\n",
       "      <td>0.166944</td>\n",
       "      <td>0.172385</td>\n",
       "      <td>0.164202</td>\n",
       "      <td>0.165802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132</td>\n",
       "      <td>0.180787</td>\n",
       "      <td>0.168680</td>\n",
       "      <td>0.165559</td>\n",
       "      <td>0.172081</td>\n",
       "      <td>0.170672</td>\n",
       "      <td>0.161155</td>\n",
       "      <td>0.164459</td>\n",
       "      <td>0.189049</td>\n",
       "      <td>0.170435</td>\n",
       "      <td>...</td>\n",
       "      <td>0.171610</td>\n",
       "      <td>0.171998</td>\n",
       "      <td>0.167248</td>\n",
       "      <td>0.173402</td>\n",
       "      <td>0.167765</td>\n",
       "      <td>0.170813</td>\n",
       "      <td>0.162381</td>\n",
       "      <td>0.188265</td>\n",
       "      <td>0.160245</td>\n",
       "      <td>0.150887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>0.167887</td>\n",
       "      <td>0.175437</td>\n",
       "      <td>0.165471</td>\n",
       "      <td>0.160461</td>\n",
       "      <td>0.169581</td>\n",
       "      <td>0.167993</td>\n",
       "      <td>0.168752</td>\n",
       "      <td>0.178969</td>\n",
       "      <td>0.159903</td>\n",
       "      <td>...</td>\n",
       "      <td>0.167696</td>\n",
       "      <td>0.172204</td>\n",
       "      <td>0.163582</td>\n",
       "      <td>0.166519</td>\n",
       "      <td>0.157531</td>\n",
       "      <td>0.165013</td>\n",
       "      <td>0.173456</td>\n",
       "      <td>0.176550</td>\n",
       "      <td>0.161843</td>\n",
       "      <td>0.160887</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   qa_id  question_asker_intent_understanding  question_body_critical  \\\n",
       "0     39                             0.167708                0.175055   \n",
       "1     46                             0.198516                0.156672   \n",
       "2     70                             0.174805                0.162797   \n",
       "3    132                             0.180787                0.168680   \n",
       "4    200                             0.167887                0.175437   \n",
       "\n",
       "   question_conversational  question_expect_short_answer  \\\n",
       "0                 0.166137                      0.160509   \n",
       "1                 0.175136                      0.164823   \n",
       "2                 0.169590                      0.162258   \n",
       "3                 0.165559                      0.172081   \n",
       "4                 0.165471                      0.160461   \n",
       "\n",
       "   question_fact_seeking  question_has_commonly_accepted_answer  \\\n",
       "0               0.170683                               0.165364   \n",
       "1               0.160392                               0.175942   \n",
       "2               0.162173                               0.167899   \n",
       "3               0.170672                               0.161155   \n",
       "4               0.169581                               0.167993   \n",
       "\n",
       "   question_interestingness_others  question_interestingness_self  \\\n",
       "0                         0.169331                       0.178417   \n",
       "1                         0.164311                       0.191221   \n",
       "2                         0.162903                       0.172595   \n",
       "3                         0.164459                       0.189049   \n",
       "4                         0.168752                       0.178969   \n",
       "\n",
       "   question_multi_intent  ...  question_well_written  answer_helpful  \\\n",
       "0               0.161578  ...               0.168833        0.172993   \n",
       "1               0.169924  ...               0.168358        0.176660   \n",
       "2               0.162429  ...               0.163683        0.168201   \n",
       "3               0.170435  ...               0.171610        0.171998   \n",
       "4               0.159903  ...               0.167696        0.172204   \n",
       "\n",
       "   answer_level_of_information  answer_plausible  answer_relevance  \\\n",
       "0                     0.163021          0.167236          0.153434   \n",
       "1                     0.169892          0.177875          0.171899   \n",
       "2                     0.165504          0.171961          0.162536   \n",
       "3                     0.167248          0.173402          0.167765   \n",
       "4                     0.163582          0.166519          0.157531   \n",
       "\n",
       "   answer_satisfaction  answer_type_instructions  answer_type_procedure  \\\n",
       "0             0.164209                  0.173853               0.177635   \n",
       "1             0.178268                  0.158517               0.185142   \n",
       "2             0.172516                  0.166944               0.172385   \n",
       "3             0.170813                  0.162381               0.188265   \n",
       "4             0.165013                  0.173456               0.176550   \n",
       "\n",
       "   answer_type_reason_explanation  answer_well_written  \n",
       "0                        0.161870             0.158824  \n",
       "1                        0.171573             0.149247  \n",
       "2                        0.164202             0.165802  \n",
       "3                        0.160245             0.150887  \n",
       "4                        0.161843             0.160887  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv('data/sample_submission.csv')\n",
    "submission.loc[:, 'question_asker_intent_understanding':] = result\n",
    "#submission.loc[~submission['qa_id'].isin(qa_id_list),'question_type_spelling']=0.0\n",
    "#submission.loc[submission['qa_id'].isin(qa_id_list),'question_type_spelling'] = 1.0\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (DL)",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
